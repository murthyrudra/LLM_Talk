{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654cf9b1-4f6a-420b-a540-31c19f5a3866",
   "metadata": {},
   "source": [
    "# Word Co-Occurrence Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd511f-4099-4072-a268-9f79b96373b5",
   "metadata": {},
   "source": [
    "## This notebook demonstrates how to obtain word co-occurrence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febeb17-30c8-4443-8c2c-27076098c57d",
   "metadata": {},
   "source": [
    "#### Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323ecdd-50fa-4cdc-90d6-1dffa6abeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56e3fa-03c6-48f5-ac8f-20082a9bac53",
   "metadata": {},
   "source": [
    "#### Let us import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb92d5-c0a9-41a0-a829-5159fc607f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164dd37-659d-43a4-9116-0de70d0f8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I like dosa',\n",
    "            'I like idli',\n",
    "            'I hate spicy food',\n",
    "            'I hate sweets'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff54d547-1325-474b-8b81-392669f2b2bb",
   "metadata": {},
   "source": [
    "## Co-Occurrence Matrix without Stop-word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9831360-6b95-4d72-a56f-a3d659b382fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = []\n",
    "\n",
    "for each_sentence in sentences:\n",
    "    tokenized_sentence.append( ' '.join( [word.lower() for word in word_tokenize(each_sentence)]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e7700-204a-4f8d-a351-c5309dba0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ef16a-a903-4589-aba9-d3578079fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary from corpus\n",
    "\n",
    "vocabulary = {}\n",
    "\n",
    "for each_sentence in tokenized_sentence:\n",
    "    for each_word in each_sentence.split(' '):\n",
    "        if each_word not in vocabulary:\n",
    "            vocabulary[each_word] = len(vocabulary)\n",
    "            \n",
    "print('Read {0} number of unique words'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223c712-9ad7-4c2e-9880-51e16e6c674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nxn matrix\n",
    "\n",
    "cooccur_matrix = np.zeros(( len(vocabulary), len(vocabulary) ))\n",
    "context_window = 3\n",
    "\n",
    "\n",
    "# for every sentence\n",
    "for each_sentence in tokenized_sentence:\n",
    "    # for every word in the sentence\n",
    "    sentence = each_sentence.split(' ')\n",
    "    for word_index in range(len(sentence)):\n",
    "        # define a context window\n",
    "        for context_window in range( 3 - word_index, 3 + word_index):\n",
    "            if context_window < 0 or context_window >= len(sentence) or context_window == word_index:\n",
    "                continue\n",
    "            cooccur_matrix[ vocabulary[sentence[word_index]]][ vocabulary[sentence[context_window]] ] += 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87101a23-8e30-4df7-b6c8-d6f61e0756a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = cooccur_matrix, columns = list(vocabulary.keys()), index = list(vocabulary.keys()))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27d290-2a6b-4100-9817-4046549d196c",
   "metadata": {},
   "source": [
    "## SVD of Word Co-Occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222bfb9-a7a1-4dae-8aef-ba572096abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "from numpy import diag\n",
    "from numpy import dot\n",
    "from numpy import array\n",
    "\n",
    "# define a matrix\n",
    "A = array(df)\n",
    "print('Matrix A is: \\n')\n",
    "print(A)\n",
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2310a2-819c-4750-8f2c-006b49d1fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform SVD\n",
    "\n",
    "U, Sigma, VT = svd(A)\n",
    "\n",
    "# Top k \n",
    "k = 3\n",
    "\n",
    "U = U[:,:k]\n",
    "Sigma = Sigma[:k]\n",
    "VT = VT[:k,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80c4fc-09db-4890-924b-f048b6614a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimReduced_df = pd.DataFrame(U, index=vocabulary)\n",
    "dimReduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f89797-5c86-433c-98d3-6145cfc4fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def display_pca_scatterplot(model, words=None):\n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.01, y+0.01, word)\n",
    "    plt.show()\n",
    "        \n",
    "        \n",
    "def display_tsne_scatterplot(model, perplexity=1.0, words=None):\n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "    twodim = TSNE(perplexity=perplexity).fit_transform(word_vectors)[:,:2]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.01, y+0.01, word)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df8198-e7bd-46d2-8794-4a047c44d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dimReduced_df.T.to_dict(orient='list')\n",
    "\n",
    "display_tsne_scatterplot(weights, perplexity=1.0, words=list(dimReduced_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be0b76-9ade-43b7-8af2-7bf444dc38b7",
   "metadata": {},
   "source": [
    "## Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b8ca5-ac5e-4af6-a4ff-17322d1e4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I like dosa',\n",
    "            'I like idli',\n",
    "            'I hate dosa',\n",
    "            'I hate sweets'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e36336-c091-485a-8075-f6a38fc5cb4d",
   "metadata": {},
   "source": [
    "## Co-Occurrence Matrix without Stop-word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1bae9-e101-41cb-80e1-1172eee1d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = []\n",
    "\n",
    "for each_sentence in sentences:\n",
    "    tokenized_sentence.append( ' '.join( [word.lower() for word in word_tokenize(each_sentence)]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8e16a-45b8-4ed7-928b-fc30f7ecd068",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac70d3-4298-42b2-a87b-1552007db543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary from corpus\n",
    "\n",
    "vocabulary = {}\n",
    "\n",
    "for each_sentence in tokenized_sentence:\n",
    "    for each_word in each_sentence.split(' '):\n",
    "        if each_word not in vocabulary:\n",
    "            vocabulary[each_word] = len(vocabulary)\n",
    "            \n",
    "print('Read {0} number of unique words'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef84ef-36f9-4b08-8e6b-5bc83f839a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nxn matrix\n",
    "\n",
    "cooccur_matrix = np.zeros(( len(vocabulary), len(vocabulary) ))\n",
    "context_window = 3\n",
    "\n",
    "\n",
    "# for every sentence\n",
    "for each_sentence in tokenized_sentence:\n",
    "    # for every word in the sentence\n",
    "    sentence = each_sentence.split(' ')\n",
    "    for word_index in range(len(sentence)):\n",
    "        # define a context window\n",
    "        for context_window in range( 3 - word_index, 3 + word_index):\n",
    "            if context_window < 0 or context_window >= len(sentence) or context_window == word_index:\n",
    "                continue\n",
    "            cooccur_matrix[ vocabulary[sentence[word_index]]][ vocabulary[sentence[context_window]] ] += 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e943a-3ea1-443e-bff2-9ac299828f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = cooccur_matrix, columns = list(vocabulary.keys()), index = list(vocabulary.keys()))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18b699-638f-4dcc-b516-aed7d4c52b03",
   "metadata": {},
   "source": [
    "## SVD of Word Co-Occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addef08-7c34-4100-8a2f-a398e0d716d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a matrix\n",
    "A = array(df)\n",
    "print('Matrix A is: \\n')\n",
    "print(A)\n",
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f2445-7fcf-4f7d-af3e-5bbe678c2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform SVD\n",
    "\n",
    "U, Sigma, VT = svd(A)\n",
    "\n",
    "# Top k \n",
    "k = 2\n",
    "\n",
    "U = U[:,:k]\n",
    "Sigma = Sigma[:k]\n",
    "VT = VT[:k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850df93-009d-4d43-ae32-8bd869065f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimReduced_df = pd.DataFrame(U, index=vocabulary)\n",
    "dimReduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd1051-3e41-4971-a92e-1cc4c3cf23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dimReduced_df.T.to_dict(orient='list')\n",
    "display_tsne_scatterplot(weights, perplexity=0.2, words=list(dimReduced_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dade8b5-a9b0-4bc7-a8c8-a46708a4887d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
