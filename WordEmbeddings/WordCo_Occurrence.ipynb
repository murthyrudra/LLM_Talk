{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654cf9b1-4f6a-420b-a540-31c19f5a3866",
   "metadata": {},
   "source": [
    "# Word Co-Occurrence Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd511f-4099-4072-a268-9f79b96373b5",
   "metadata": {},
   "source": [
    "## This notebook demonstrates how to obtain word co-occurrence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febeb17-30c8-4443-8c2c-27076098c57d",
   "metadata": {},
   "source": [
    "#### Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323ecdd-50fa-4cdc-90d6-1dffa6abeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56e3fa-03c6-48f5-ac8f-20082a9bac53",
   "metadata": {},
   "source": [
    "#### Let us import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb92d5-c0a9-41a0-a829-5159fc607f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164dd37-659d-43a4-9116-0de70d0f8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [ 'I am not sleeping, I am waking, Would you know what I am making? I am boiling warm beer with butter,  Will you be my guest for supper?', \n",
    "            'Home! home! look at the shoe! Princess! the shoe was made for you! Prince! prince! take home thy bride, For she is the true one that sits by thy side!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff54d547-1325-474b-8b81-392669f2b2bb",
   "metadata": {},
   "source": [
    "## Co-Occurrence Matrix without Stop-word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9831360-6b95-4d72-a56f-a3d659b382fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = []\n",
    "\n",
    "for each_sentence in sentences:\n",
    "    tokenized_sentence.append( ' '.join( [word.lower() for word in word_tokenize(each_sentence)]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e7700-204a-4f8d-a351-c5309dba0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ef16a-a903-4589-aba9-d3578079fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary from corpus\n",
    "\n",
    "vocabulary = {}\n",
    "\n",
    "for each_sentence in tokenized_sentence:\n",
    "    for each_word in each_sentence.split(' '):\n",
    "        if each_word not in vocabulary:\n",
    "            vocabulary[each_word] = len(vocabulary)\n",
    "            \n",
    "print('Read {0} number of unique words'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223c712-9ad7-4c2e-9880-51e16e6c674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nxn matrix\n",
    "\n",
    "cooccur_matrix = np.zeros(( len(vocabulary), len(vocabulary) ))\n",
    "context_window = 3\n",
    "\n",
    "\n",
    "# for every sentence\n",
    "for each_sentence in tokenized_sentence:\n",
    "    # for every word in the sentence\n",
    "    sentence = each_sentence.split(' ')\n",
    "    for word_index in range(len(sentence)):\n",
    "        # define a context window\n",
    "        for context_window in range( 3 - word_index, 3 + word_index):\n",
    "            if context_window < 0 or context_window >= len(sentence) or context_window == word_index:\n",
    "                continue\n",
    "            cooccur_matrix[ vocabulary[sentence[word_index]]][ vocabulary[sentence[context_window]] ] += 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87101a23-8e30-4df7-b6c8-d6f61e0756a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = cooccur_matrix, columns = list(vocabulary.keys()), index = list(vocabulary.keys()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2cd53-2e4e-4c87-9840-7291f49773bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ ['prince', 'princess', 'sleeping', 'waking', 'beer', 'butter'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddfc96-0ac2-4146-a0dc-03030b669eda",
   "metadata": {},
   "source": [
    "## Co-Occurrence Matrix with Stop-Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56abd0c-89f9-4830-a335-772600746681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "\n",
    "english_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb644d-06eb-4ab4-a0e3-a7fda00f14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = []\n",
    "\n",
    "for each_sentence in sentences:\n",
    "    temp_sentence = []\n",
    "    for word in word_tokenize(each_sentence):\n",
    "        if word.lower() not in english_stop_words and word.lower() not in punctuation:\n",
    "            temp_sentence.append( word.lower())\n",
    "    tokenized_sentence.append( ' '.join(temp_sentence) )\n",
    "    \n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73fd0c-4b2e-41d6-8a1b-9ead8d9622d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary from corpus\n",
    "\n",
    "vocabulary = {}\n",
    "\n",
    "for each_sentence in tokenized_sentence:\n",
    "    for each_word in each_sentence.split(' '):\n",
    "        if each_word not in vocabulary:\n",
    "            vocabulary[each_word] = len(vocabulary)\n",
    "            \n",
    "print('Read {0} number of unique words'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb3687-8567-4c72-99ca-afb37c92a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nxn matrix\n",
    "\n",
    "cooccur_matrix = np.zeros(( len(vocabulary), len(vocabulary) ))\n",
    "context_window = 3\n",
    "\n",
    "\n",
    "# for every sentence\n",
    "for each_sentence in tokenized_sentence:\n",
    "    # for every word in the sentence\n",
    "    sentence = each_sentence.split(' ')\n",
    "    for word_index in range(len(sentence)):\n",
    "        # define a context window\n",
    "        for context_window in range( 3 - word_index, 3 + word_index):\n",
    "            if context_window < 0 or context_window >= len(sentence) or context_window == word_index:\n",
    "                continue\n",
    "            cooccur_matrix[ vocabulary[sentence[word_index]]][ vocabulary[sentence[context_window]] ] += 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a84d0-e0bd-4198-b5d2-870af3dd6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = cooccur_matrix, columns = list(vocabulary.keys()), index = list(vocabulary.keys()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b495aa4-2bad-4bc6-8924-3777206104ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ ['prince', 'princess', 'sleeping', 'waking', 'beer', 'butter'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc13fb1-8cbe-43e7-b1d2-23d31d3a620f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
