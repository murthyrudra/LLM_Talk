{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b7b2aa-9380-4bb0-bb43-e59c3f3b37cb",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636bc414-33d1-4974-a283-a1a29dd977ec",
   "metadata": {},
   "source": [
    "## This notebook demonstrates how to obtain one-hot encoding for words given a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2035c-eb30-4a98-b735-d42adb3301fa",
   "metadata": {},
   "source": [
    "#### Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573d5c8-7378-42d0-8fe2-476d4f9048ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47edba4-5069-4bcd-a458-dd3d5bc499c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Let us import necessary packages and download Gutenberg Corpus from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04932c-254d-4978-b081-5eb58c8a2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "# nltk.download('brown')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c9664-98a7-4208-806d-8e84f6d0d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shakespeare Macbeth\n",
    "corpus = gutenberg.sents('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf33d17-ce29-4baf-a4c1-f59ccd247bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc8c46-2684-44bd-9241-f8faa427e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ ' '.join(sentences) for sentences in corpus]\n",
    "\n",
    "corpus = [ 'I liked the movie very much', 'The movie was very bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8a759-dbfb-45e8-af97-d91725e19fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536f3ec-770d-4a87-bc56-5067dc982c13",
   "metadata": {},
   "source": [
    "#### Let us now create one-hot vector for every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19235f56-eb78-4883-851f-8e535bc7e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary\n",
    "\n",
    "vocabulary = {}\n",
    "\n",
    "for every_sentence in corpus:\n",
    "    for every_word in every_sentence.split(' '):\n",
    "        if every_word not in vocabulary:\n",
    "            vocabulary[every_word] = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9bd74-f5e1-425e-8683-6bd3c0a687fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32501c1f-658c-4d55-91b6-b972ec30af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total unique words in the corpus is {0}'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03f23d-959b-4b57-9a5e-80c45378b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = {}\n",
    "\n",
    "for each_word in vocabulary:\n",
    "    arr = list(np.zeros(len(vocabulary), dtype = int))\n",
    "    arr[ vocabulary[each_word] ] = 1\n",
    "    \n",
    "    one_hot_encoding[each_word] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8e27d-795d-4fac-8ff4-71aa9b6d46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'the'\n",
    "\n",
    "if word in one_hot_encoding:\n",
    "    print(one_hot_encoding[word])\n",
    "else:\n",
    "    print('{0} not present, try a different word'.format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6128280-c0c1-4bd9-8c7a-d6f89dd0c879",
   "metadata": {},
   "source": [
    "## Bag Of Words Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afabb50-62d9-4552-ba0e-e9dad4e24c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BOW representation for a sentence\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd559f49-8372-433f-98e4-71fd48b8f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add \n",
    "\n",
    "sentence_rep = one_hot_encoding['I']\n",
    "\n",
    "for each_word in corpus[0].split(' ')[1:]:\n",
    "    sentence_rep = list(map(add, sentence_rep, one_hot_encoding[each_word]))\n",
    "\n",
    "sentence_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c5695-e166-495e-a7c6-b1606eea898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_rep = one_hot_encoding['The']\n",
    "\n",
    "for each_word in corpus[1].split(' ')[1:]:\n",
    "    sentence_rep = list(map(add, sentence_rep, one_hot_encoding[each_word]))\n",
    "\n",
    "sentence_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a3ddb-71ce-4052-aadb-3573bd732837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
